------------------------------------------------------------------------------
\\
arXiv:2101.04792
From: Nikolay Mikhaylovskiy <example@example.com>
Date: Tue, 12 Jan 2021 22:55:17 GMT   (610kb)
Date (revised v2): Sat, 30 Jan 2021 16:48:16 GMT   (610kb)
Date (revised v3): Fri, 16 Apr 2021 21:11:36 GMT   (972kb)
Date (revised v4): Fri, 4 Jun 2021 22:20:46 GMT   (806kb)

Title: Learning Efficient Representations for Keyword Spotting with Triplet
  Loss
Authors: Roman Vygon, Nikolay Mikhaylovskiy
Categories: eess.AS cs.AI cs.LG
Comments: Submitted to SPECOM 2021
Journal-ref: In: Karpov A., Potapova R. (eds) Speech and Computer. SPECOM 2021.
  Lecture Notes in Computer Science, vol 12997. Springer, Cham
DOI: 10.1007/978-3-030-87802-3_69
License: http://arxiv.org/licenses/nonexclusive-distrib/1.0/
\\
  In the past few years, triplet loss-based metric embeddings have become a
de-facto standard for several important computer vision problems, most
no-tably, person reidentification. On the other hand, in the area of speech
recognition the metric embeddings generated by the triplet loss are rarely used
even for classification problems. We fill this gap showing that a combination
of two representation learning techniques: a triplet loss-based embedding and a
variant of kNN for classification instead of cross-entropy loss significantly
(by 26% to 38%) improves the classification accuracy for convolutional networks
on a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel
phonetic similarity based triplet mining approach. We also improve the current
best published SOTA for Google Speech Commands dataset V1 10+2 -class
classification by about 34%, achieving 98.55% accuracy, V2 10+2-class
classification by about 20%, achieving 98.37% accuracy, and V2 35-class
classification by over 50%, achieving 97.0% accuracy.
\\
